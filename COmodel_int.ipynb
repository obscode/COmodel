{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b975ea",
   "metadata": {},
   "source": [
    "# Fitting CO model interactively\n",
    "\n",
    "Load up a spectrum and play with the widgets to get a good initial starting point for the fit. The next cell is to setup some variables:  which file to load, what the columns are called, and the wavelength region to fit. Also, choose a `scale` that puts your spectrum near unity.\n",
    "\n",
    "Aside from the usual modules, you'll need the `ipympl` and `george` packages, which can be installed with `conda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsfile = \"SN2016adj_20160521_BAA_NIR_cc_dered_rest.ecsv\"\n",
    "wavecol = 'wave'\n",
    "fluxcol = 'flux'\n",
    "wmin = 22800\n",
    "wmax = 24950\n",
    "scale = 1e-15\n",
    "# Pickle file with Peter's grid of models\n",
    "pklfile = \"opac_fine.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ea211",
   "metadata": {},
   "source": [
    "## Getting a first guess fit\n",
    "\n",
    "Running this next cell will give you an interactive plot where you can use the sliders to both see how the different parameters change the model, but also use chi-by-eye to get a good initial starting point for optimizers or MCMC inference. Note that if you don't set the `scale` parameter appropriately, you might not see anything with the default model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits, ascii\n",
    "import COmodel\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "tab = ascii.read(fitsfile)\n",
    "wave,flux = tab[wavecol].value, tab[fluxcol].value\n",
    "gids = np.greater(wave, wmin) & np.less(wave, wmax)\n",
    "wave,flux = wave[gids],flux[gids]\n",
    "\n",
    "model = COmodel.FluxModel(pkl=pklfile, scale=scale)\n",
    "model.set_pars([3000, 2000, -3, 1, 0, 3])\n",
    "\n",
    "%matplotlib notebook\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(wave,flux/scale,'-')\n",
    "ax.set_xlabel('Wavelength (Angstroms)')\n",
    "ax.set_ylabel('scaled Flux')\n",
    "\n",
    "line, = ax.plot(wave, model(wave), '-')\n",
    "\n",
    "def updateA(change):\n",
    "    model.A = change.new\n",
    "    line.set_ydata(model(wave))\n",
    "\n",
    "def updateT(change):\n",
    "    model.T = change.new\n",
    "    line.set_ydata(model(wave))\n",
    "\n",
    "def updateV(change):\n",
    "    model.vel = change.new\n",
    "    line.set_ydata(model(wave))\n",
    "\n",
    "def updatelco(change):\n",
    "    model.lco = change.new\n",
    "    line.set_ydata(model(wave))\n",
    "\n",
    "def updatez(change):\n",
    "    model.z = change.new\n",
    "    line.set_ydata(model(wave))\n",
    "    \n",
    "def updateb(change):\n",
    "    model.b = change.new\n",
    "    line.set_ydata(model(wave))\n",
    "    \n",
    "Aslider = widgets.FloatSlider(\n",
    "    value=1, min=0, max=5.0, step=0.01, description='Aplitude:',\n",
    "    disabled=False, continuous_update=True, orientation='horizontal',\n",
    "    readout=True, readout_format='.2f')\n",
    "Tslider = widgets.FloatSlider(\n",
    "   value=3000, min=model.T.min, max=model.T.max, step=(model.T.max-model.T.min)/100,\n",
    "   description='Temperature:', continuous_update=True, readout=True, readout_format='.1f')\n",
    "vslider = widgets.FloatSlider(\n",
    "   value=2000, min=model.vel.min, max=model.vel.max, step=(model.vel.max-model.vel.min)/100,\n",
    "   description='velocity:', continuous_update=True, readout=True, readout_format='.1f')\n",
    "lslider = widgets.FloatSlider(\n",
    "   value=-3, min=model.lco.min, max=model.lco.max, step=(model.lco.max-model.lco.min)/100,\n",
    "   description='log(CO+/CO)', continuous_update=True, readout=True, readout_format='.1f')\n",
    "zslider = widgets.FloatSlider(\n",
    "   value=0, min=0, max=5e-3, step=1e-5,\n",
    "   description='z:', continuous_update=True, readout=True, readout_format='.1e')\n",
    "bslider = widgets.FloatSlider(\n",
    "   value=3, min=0, max=10, step=0.01,\n",
    "   description='continuum:', continuous_update=True, readout=True, readout_format='.1e')\n",
    "\n",
    "\n",
    "Aslider.observe(updateA, 'value')\n",
    "Tslider.observe(updateT, 'value')\n",
    "vslider.observe(updateV, 'value')\n",
    "lslider.observe(updatelco, 'value')\n",
    "zslider.observe(updatez, 'value')\n",
    "bslider.observe(updateb, 'value')\n",
    "widgets.VBox([Aslider,Tslider,vslider,lslider,zslider,bslider])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2c9d7",
   "metadata": {},
   "source": [
    "## Masking the Data\n",
    "\n",
    "In this next cell, the residuals from the fit made above are plotted. Now is the time to remove bad data. You can do this two ways:  interactively set the threshold for sigma-clipping (defaulted to 10-sigma) or selecting ranges to mask. The latter is done by clicking a dragging a wavelength region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204e01f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.modeling import fitting\n",
    "from matplotlib.widgets import SpanSelector\n",
    "import warnings\n",
    "\n",
    "# Threshold for keeping data in units of MAD\n",
    "thresh = 10\n",
    "\n",
    "# Get an optimized fit\n",
    "fitter = fitting.LevMarLSQFitter()\n",
    "opt = fitter(model, wave, flux/scale)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(wave,flux/scale-model(wave),'-', color='k', alpha=0.1)\n",
    "ax.set_xlabel('Wavelength (Angstroms)')\n",
    "ax.set_ylabel('scaled Flux Residuals')\n",
    "\n",
    "ax.plot(wave, 0*wave, '-', color='C1')\n",
    "\n",
    "mask = np.isnan(wave)    # initial mask\n",
    "sigma = 1.5*np.absolute(np.median(flux/scale-model(wave)))    # MAD to avoid large outliers\n",
    "siglin1 = ax.axhline(sigma, ls='--', color='C1')\n",
    "siglin2 = ax.axhline(-sigma, ls='--', color='C1')\n",
    "\n",
    "mask = np.greater(np.absolute(flux/scale-model(wave)), thresh*sigma)\n",
    "datline, = ax.plot(wave[~mask], flux[~mask]/scale-model(wave)[~mask], '-', color='C0')\n",
    "\n",
    "# Refit using mask and errors\n",
    "opt = fitter(opt, wave[~mask], flux[~mask]/scale, weights=np.power(flux[~mask]*0 + sigma,-1))\n",
    "sigma = 1.5*np.absolute(np.median(flux[~mask]/scale-model(wave[~mask])))\n",
    "\n",
    "Xstart = None      # state variable\n",
    "def on_Select(xmin,xmax):\n",
    "    global datline\n",
    "    gids = np.greater(wave, xmin) & np.less(wave, xmax)\n",
    "    mask[gids] = True\n",
    "    datline.remove()\n",
    "    datline, = ax.plot(wave[~mask], flux[~mask]/scale-model(wave)[~mask], '-', color='C0')\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def updateThresh(change):\n",
    "    global datline\n",
    "    thresh = change.new\n",
    "    mask = np.greater(np.absolute(flux/scale-model(wave)), thresh*sigma)\n",
    "    datline.remove()\n",
    "    datline, = ax.plot(wave[~mask], flux[~mask]/scale-model(wave)[~mask], '-', color='C0')\n",
    "    \n",
    "ThreshSlider = widgets.FloatSlider(\n",
    "   value=10, min=1, max=20, step=0.1,\n",
    "   description='continuum:', continuous_update=False, readout=True)\n",
    "ThreshSlider.observe(updateThresh, 'value')\n",
    "span = SpanSelector(ax, on_Select, \"horizontal\", props=dict(alpha=0.1, facecolor='red'), interactive=False,\n",
    "            drag_from_anywhere=True)\n",
    "\n",
    "plt.show()\n",
    "ThreshSlider\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb26db1",
   "metadata": {},
   "source": [
    "## Modeling the Noise\n",
    "\n",
    "The initial modeling was done assuming some constant white noise over the entire spectrum. Now we try to be a bit more careful. In this next cell, we model the noise as a Gaussian Process with the `Matern32` kernel. This allows for correlated noise at a level `alpha` and scale length `kscale`. A white noise component of `sigma` is retained. We just use an optimizer in this case, since we just want to know what `alpha` and `kscale` best describe the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf44147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import george\n",
    "from george import kernels\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Start with a scale that's likely to be close:\n",
    "kscale = np.mean(wave[1:]-wave[:-1])*10\n",
    "resids = flux[~mask]/scale - model(wave[~mask])\n",
    "alpha = np.var(resids)\n",
    "print(\"Initial kernel params:  alpha={}, scale={}\".format(alpha, kscale))\n",
    "gp = george.GP(alpha*kernels.Matern32Kernel(kscale))\n",
    "gp.compute(wave[~mask], flux[~mask]*0+sigma)\n",
    "\n",
    "# intial starting point\n",
    "init = gp.get_parameter_vector()\n",
    "\n",
    "def mlnprob(p):\n",
    "    '''A function to return the negative log-probability. Used with minimize()'''\n",
    "    gp.set_parameter_vector(p)\n",
    "    return -gp.log_likelihood(resids, quiet=True) - gp.log_prior()\n",
    "gp_p = minimize(mlnprob, init)\n",
    "\n",
    "print(gp_p)\n",
    "print(\"Final kernel params: alpha={}, scale={}\".format(np.exp(gp_p.x[0]),np.exp(gp_p.x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e6ed5",
   "metadata": {},
   "source": [
    "## Visualizing the noise\n",
    "\n",
    "This next cell, when run, will plot the best-fit CO model with the white noise `sigma` and the correlated noise side-by-side, for comparison. This can take a little while to run the first time, so you can skip it without affecting the rest of the notebook's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ef549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axes = plt.subplots(1,2, figsize=(10,4))\n",
    "axes[0].plot(wave, model(wave)+np.random.normal(0, sigma, size=len(wave)), '-')\n",
    "axes[0].plot(wave, model(wave),'-', zorder=20)\n",
    "axes[0].set_xlabel('Wavelength (Angstroms)')\n",
    "axes[0].set_ylabel('Simulated Flux + (white noise)')\n",
    "\n",
    "gp.set_parameter_vector(gp_p.x)\n",
    "gp.compute(wave, wave*0+sigma)\n",
    "axes[1].plot(wave, model(wave)+gp.sample_conditional(wave*0, wave), '-')\n",
    "axes[1].plot(wave, model(wave),'-', zorder=20)\n",
    "axes[1].set_xlabel('Wavelength (Angstroms)')\n",
    "axes[1].set_ylabel('Simulated Flux + (correlated noise)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beba0e8",
   "metadata": {},
   "source": [
    "## Fitting with Correlated noise\n",
    "\n",
    "Now for the main event:  use `emcee` to both optimize and infer the uncertainties in the paramters. Note that because we are now multiplying the residuals vector by the inverse of the covariance matrix, this takes significantly longer than the usual white-noise chi-square. In the call to `emcee.EnsembleSampler` below, you can replace the `lnprobCorr` with `lnprobWhite` to just use white noise and speed up the computation.\n",
    "\n",
    "Also, the level and scale of the correlated noise (`alpha` and `kscale`) are kept *fixed*. One could also make them  variables and use `emcee` to infer their values along with the parameters of interest. But that means *inverting* an NxN matrix at each iteration, which can make the problem unreasonably slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab61301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import emcee\n",
    "from scipy.stats import norm\n",
    "Pool = mp.get_context('fork').Pool\n",
    "\n",
    "def lnprior(p):\n",
    "    pars = [par for par in model.param_names if not model.fixed[par]]\n",
    "    for i,par in enumerate(pars):\n",
    "        pmin,pmax = model.bounds[par]\n",
    "        if pmin is not None and p[i] < pmin:  return -np.inf\n",
    "        if pmax is not None and p[i] > pmax:  return -np.inf\n",
    "    return 0\n",
    "\n",
    "gp.set_parameter_vector(gp_p.x)\n",
    "gp.compute(wave[~mask], flux[~mask]*0+sigma)\n",
    "def lnprobCorr(p):\n",
    "    lp = lnprior(p)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    model.set_pars(p)\n",
    "    diff = (flux[~mask]/scale - model(wave[~mask]))\n",
    "    return lp+gp.log_likelihood(diff, quiet=True)\n",
    "\n",
    "def lnprobWhite(p):\n",
    "    lp = lnprior(p)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    model.set_pars(p)\n",
    "    diff = (flux[~mask]/scale - model(wave[~mask]))\n",
    "    lp += np.sum(norm.logpdf(diff, loc=0, scale=wave[~mask]*0+sigma))\n",
    "    return lp\n",
    "\n",
    "p0 = opt.parameters + 1e-8*np.random.randn(200, len(opt.parameters))\n",
    "with Pool() as pool:\n",
    "    # Replace lnprobCorr with lnprobWhite if you want to just do the white noise errors\n",
    "    sampler2 = emcee.EnsembleSampler(200, len(opt.parameters), lnprobCorr)\n",
    "    sampler2.run_mcmc(p0, 1000, progress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a2e20",
   "metadata": {},
   "source": [
    "## Visualizing the results.\n",
    "\n",
    "The next cell plots the traces of the MCMC runs. This will allow you to choose the \"burn-in\" time. Choose an interation where you think the chains have settled to their final distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703abdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler2.get_chain()\n",
    "COmodel.plotTraces(samples, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8129e",
   "metadata": {},
   "source": [
    "Now, set the correct burn-in time (default is 500 iterations). Then run the rest of the cells to get the results and diagnostic plots. Note that for the best-fit values of the CO amplitude (`A`) and cotinuum level (`b`), the units will be `scale` $erg \\cdot s^{-1} \\cdot cm^{-2} \\cdot AA^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3682f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nburn = 500\n",
    "\n",
    "fmts = {\"T\":\"{:.0f}\", \"vel\":\"{:.0f}\", \"lco\":\"{:.2f}\", \"A\":\"{:.2f}\", \"z\":\"{:.5f}\",\"b\":\"{:.2f}\"}\n",
    "meds = np.median(samples[Nburn:,:,:], axis=(0,1))\n",
    "stds = np.std(samples[Nburn:,:,:], axis=(0,1))\n",
    "for i,par in enumerate(model.param_names):\n",
    "    fmt = \"{}:  \" + fmts[par] + \" +/- \" + fmts[par]\n",
    "    print(fmt.format(par, meds[i], stds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = COmodel.plotCorner(samples[Nburn:,:,:], meds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ff059",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = COmodel.plotFit(wave, flux/scale, flux*0+sigma, meds, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
